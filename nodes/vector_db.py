"""
ë²¡í„° DB ê´€ë ¨ ë…¸ë“œ
- Pinecone (ìš°ì„ ) ë˜ëŠ” ChromaDBì— ì„ë² ë”©í•˜ì—¬ ì €ì¥
- í‹€ë¦° ë¬¸ì œë¥¼ ë³„ë„ ì»¬ë ‰ì…˜ì— ì €ì¥
"""

import json
import os
import time
from typing import Dict, List, Optional
from langchain_openai import OpenAIEmbeddings
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# Pinecone ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
USE_PINECONE = bool(os.getenv("PINECONE_API_KEY"))

if USE_PINECONE:
    try:
        from pinecone import Pinecone, ServerlessSpec
        print("âœ“ Pinecone í´ë¼ìš°ë“œ ë²¡í„° DB ì‚¬ìš©")
    except ImportError:
        print("âš ï¸ Pinecone íŒ¨í‚¤ì§€ ì—†ìŒ. ChromaDB ì‚¬ìš©")
        USE_PINECONE = False

if not USE_PINECONE:
    import chromadb
    from chromadb.config import Settings
    print("âœ“ ChromaDB ë¡œì»¬ ë²¡í„° DB ì‚¬ìš©")


class QuestionVectorDB:
    """ë¬¸ì œ ë²¡í„° DB ê´€ë¦¬ í´ë˜ìŠ¤ (Pinecone ë˜ëŠ” ChromaDB)"""

    def __init__(self, persist_directory: str = "vector_store"):
        self.persist_directory = persist_directory
        self.use_pinecone = USE_PINECONE
        self.embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small"
        )
        self.dimension = 1536  # text-embedding-3-small ì°¨ì›

        if self.use_pinecone:
            # Pinecone í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            self.pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
        else:
            # ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            self.client = chromadb.PersistentClient(
                path=persist_directory,
                settings=Settings(
                    anonymized_telemetry=False,
                    allow_reset=True
                )
            )

    def _create_question_text(self, question: Dict) -> str:
        """ë¬¸ì œë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        text_parts = [
            f"ë¬¸ì œ {question.get('ë¬¸ì œë²ˆí˜¸', '')}ë²ˆ",
            f"ì¶œì²˜: {question.get('ì¶œì²˜', '')}",
            f"ë‚´ìš©: {question.get('ë¬¸ì œë‚´ìš©', '')}",
        ]

        if question.get('ì½”ë“œ'):
            text_parts.append(f"ì½”ë“œ: {question.get('ì½”ë“œ', '')}")

        return "\n".join(text_parts)

    def _get_index_name(self, question_type: str) -> str:
        """ì¸ë±ìŠ¤/ì»¬ë ‰ì…˜ ì´ë¦„ ìƒì„±"""
        return f"gisa-{question_type}-questions"

    # ==================== Pinecone ë©”ì„œë“œ ====================

    def _initialize_pinecone_index(self, question_type: str, questions: List[Dict]):
        """Pinecone ì¸ë±ìŠ¤ ì´ˆê¸°í™” (ë°°ì¹˜ ì„ë² ë”©)"""
        index_name = self._get_index_name(question_type)

        # ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ
        if index_name in self.pc.list_indexes().names():
            print(f"ê¸°ì¡´ Pinecone ì¸ë±ìŠ¤ '{index_name}' ì‚­ì œ")
            self.pc.delete_index(index_name)
            time.sleep(1)

        # ìƒˆ ì¸ë±ìŠ¤ ìƒì„±
        print(f"Pinecone ì¸ë±ìŠ¤ '{index_name}' ìƒì„± ì¤‘...")
        self.pc.create_index(
            name=index_name,
            dimension=self.dimension,
            metric="cosine",
            spec=ServerlessSpec(
                cloud="aws",
                region="us-east-1"
            )
        )

        # ì¸ë±ìŠ¤ ì¤€ë¹„ ëŒ€ê¸°
        print(f"ì¸ë±ìŠ¤ ì¤€ë¹„ ì¤‘...")
        time.sleep(5)
        index = self.pc.Index(index_name)

        # ë¬¸ì œë“¤ ì„ë² ë”©í•˜ì—¬ ì €ì¥
        print(f"\n{question_type} ë¬¸ì œ {len(questions)}ê°œë¥¼ Pineconeì— ì €ì¥ ì¤‘...")
        print(f"ğŸ“Š ë°°ì¹˜ ì„ë² ë”© ìƒì„± ì¤‘... (OpenAI API í˜¸ì¶œ)")

        # ëª¨ë“  ë¬¸ì œ í…ìŠ¤íŠ¸ ìƒì„± (ë°°ì¹˜)
        question_texts = [self._create_question_text(q) for q in questions]

        # ë°°ì¹˜ ì„ë² ë”© ìƒì„± (í•œ ë²ˆì˜ API í˜¸ì¶œ!)
        embeddings = self.embeddings.embed_documents(question_texts)
        print(f"âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ!")

        # ë²¡í„° ì¤€ë¹„
        print(f"ğŸ“¤ Pineconeì— ì—…ë¡œë“œ ì¤‘...")
        vectors = []
        for i, (question, embedding) in enumerate(zip(questions, embeddings)):
            metadata = {
                "question_number": question.get('ë¬¸ì œë²ˆí˜¸', 0),
                "source": question.get('ì¶œì²˜', ''),
                "has_code": bool(question.get('ì½”ë“œ')),
                "score": question.get('ì ìˆ˜', 0),
                "answer": question.get('ë‹µ', ''),
                "text": question_texts[i],
                "full_question": json.dumps(question, ensure_ascii=False)
            }

            vectors.append({
                "id": f"q_{i}",
                "values": embedding,
                "metadata": metadata
            })

        # ë°°ì¹˜ë¡œ ì—…ë¡œë“œ
        index.upsert(vectors=vectors)
        print(f"âœ… {len(questions)}ê°œ ë¬¸ì œ Pinecone ì €ì¥ ì™„ë£Œ!\n")

    def _get_pinecone_index(self, question_type: str):
        """Pinecone ì¸ë±ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
        index_name = self._get_index_name(question_type)

        if index_name not in self.pc.list_indexes().names():
            raise ValueError(f"ì¸ë±ìŠ¤ '{index_name}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        return self.pc.Index(index_name)

    def _search_pinecone(self, index, query_text: str, top_k: int = 3) -> List[Dict]:
        """Pineconeì—ì„œ ìœ ì‚¬ ë¬¸ì œ ê²€ìƒ‰"""
        # ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = self.embeddings.embed_query(query_text)

        # ê²€ìƒ‰
        results = index.query(
            vector=query_embedding,
            top_k=top_k,
            include_metadata=True
        )

        # ê²°ê³¼ ë³€í™˜
        questions = []
        for match in results['matches']:
            full_question = json.loads(match['metadata']['full_question'])
            questions.append(full_question)

        return questions

    def _save_to_pinecone_wrong(self, question: Dict, user_answer: str):
        """Pineconeì— í‹€ë¦° ë¬¸ì œ ì €ì¥"""
        index_name = "gisa-wrong-questions"

        # ì¸ë±ìŠ¤ ì—†ìœ¼ë©´ ìƒì„±
        if index_name not in self.pc.list_indexes().names():
            self.pc.create_index(
                name=index_name,
                dimension=self.dimension,
                metric="cosine",
                spec=ServerlessSpec(cloud="aws", region="us-east-1")
            )
            time.sleep(5)

        index = self.pc.Index(index_name)

        # ë¬¸ì œ í…ìŠ¤íŠ¸ ìƒì„±
        question_text = self._create_question_text(question)
        embedding = self.embeddings.embed_query(question_text)

        # ì €ì¥
        doc_id = f"wrong_{int(time.time() * 1000)}"
        index.upsert(vectors=[{
            "id": doc_id,
            "values": embedding,
            "metadata": {
                "question_number": question.get('ë¬¸ì œë²ˆí˜¸', 0),
                "user_answer": user_answer,
                "correct_answer": question.get('ë‹µ', ''),
                "timestamp": time.time(),
                "text": question_text,
                "full_question": json.dumps(question, ensure_ascii=False)
            }
        }])

        print(f"âŒ í‹€ë¦° ë¬¸ì œê°€ Pinecone ë³µìŠµ DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # ==================== ChromaDB ë©”ì„œë“œ ====================

    def _initialize_chroma_collection(self, question_type: str, questions: List[Dict]):
        """ChromaDB ì»¬ë ‰ì…˜ ì´ˆê¸°í™” (ë°°ì¹˜ ì„ë² ë”©)"""
        collection_name = f"{question_type}_questions"

        # ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ í›„ ì¬ìƒì„±
        try:
            self.client.delete_collection(collection_name)
            print(f"ê¸°ì¡´ {collection_name} ì»¬ë ‰ì…˜ ì‚­ì œ")
        except:
            pass

        # ì»¬ë ‰ì…˜ ìƒì„±
        collection = self.client.create_collection(
            name=collection_name,
            metadata={"hnsw:space": "cosine"}
        )

        print(f"\n{question_type} ë¬¸ì œ {len(questions)}ê°œë¥¼ ChromaDBì— ì €ì¥ ì¤‘...")
        print(f"ğŸ“Š ë°°ì¹˜ ì„ë² ë”© ìƒì„± ì¤‘... (OpenAI API í˜¸ì¶œ)")

        # ëª¨ë“  ë¬¸ì œ í…ìŠ¤íŠ¸ ìƒì„± (ë°°ì¹˜)
        question_texts = [self._create_question_text(q) for q in questions]

        # ë°°ì¹˜ ì„ë² ë”© ìƒì„± (í•œ ë²ˆì˜ API í˜¸ì¶œ!)
        embeddings = self.embeddings.embed_documents(question_texts)
        print(f"âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ!")

        # ChromaDBì— ë°°ì¹˜ë¡œ ì €ì¥
        print(f"ğŸ’¾ ChromaDBì— ì €ì¥ ì¤‘...")
        collection.add(
            ids=[f"q_{i}" for i in range(len(questions))],
            embeddings=embeddings,
            documents=question_texts,
            metadatas=[{
                "question_number": q.get('ë¬¸ì œë²ˆí˜¸', 0),
                "source": q.get('ì¶œì²˜', ''),
                "has_code": bool(q.get('ì½”ë“œ')),
                "score": q.get('ì ìˆ˜', 0),
                "answer": q.get('ë‹µ', ''),
                "full_question": json.dumps(q, ensure_ascii=False)
            } for q in questions]
        )

        print(f"âœ… {len(questions)}ê°œ ë¬¸ì œ ChromaDB ì €ì¥ ì™„ë£Œ!\n")
        return collection

    def _get_chroma_collection(self, question_type: str):
        """ChromaDB ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸°"""
        collection_name = f"{question_type}_questions"
        return self.client.get_collection(collection_name)

    def _search_chroma(self, collection, query_text: str, top_k: int = 3) -> List[Dict]:
        """ChromaDBì—ì„œ ìœ ì‚¬ ë¬¸ì œ ê²€ìƒ‰"""
        # ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = self.embeddings.embed_query(query_text)

        # ê²€ìƒ‰
        results = collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
            include=["metadatas"]
        )

        # ê²°ê³¼ ë³€í™˜
        questions = []
        if results['metadatas']:
            for metadata in results['metadatas'][0]:
                full_question = json.loads(metadata['full_question'])
                questions.append(full_question)

        return questions

    def _save_to_chroma_wrong(self, question: Dict, user_answer: str):
        """ChromaDBì— í‹€ë¦° ë¬¸ì œ ì €ì¥"""
        # wrong_questions ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
        try:
            collection = self.client.get_collection("wrong_questions")
        except:
            collection = self.client.create_collection(
                name="wrong_questions",
                metadata={"hnsw:space": "cosine"}
            )

        # ë¬¸ì œ í…ìŠ¤íŠ¸ ìƒì„±
        question_text = self._create_question_text(question)
        embedding = self.embeddings.embed_query(question_text)

        # ê³ ìœ  ID ìƒì„±
        doc_id = f"wrong_{int(time.time() * 1000)}"

        # ChromaDBì— ì €ì¥
        collection.add(
            ids=[doc_id],
            embeddings=[embedding],
            documents=[question_text],
            metadatas=[{
                "question_number": question.get('ë¬¸ì œë²ˆí˜¸', 0),
                "user_answer": user_answer,
                "correct_answer": question.get('ë‹µ', ''),
                "timestamp": time.time(),
                "full_question": json.dumps(question, ensure_ascii=False)
            }]
        )

        print(f"âŒ í‹€ë¦° ë¬¸ì œê°€ ChromaDB ë³µìŠµ DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # ==================== ê³µí†µ ì¸í„°í˜ì´ìŠ¤ ====================

    def initialize_questions(self, question_type: str = "code"):
        """ë¬¸ì œë“¤ì„ ë²¡í„° DBì— ì €ì¥ (Pinecone ë˜ëŠ” ChromaDB)"""
        # JSON íŒŒì¼ ë¡œë“œ
        json_file = f"{question_type}_questions.json"
        if not os.path.exists(json_file):
            raise FileNotFoundError(f"{json_file} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

        with open(json_file, 'r', encoding='utf-8') as f:
            questions = json.load(f)

        if self.use_pinecone:
            self._initialize_pinecone_index(question_type, questions)
        else:
            self._initialize_chroma_collection(question_type, questions)

    def get_collection(self, question_type: str = "code"):
        """ì»¬ë ‰ì…˜/ì¸ë±ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
        if self.use_pinecone:
            return self._get_pinecone_index(question_type)
        else:
            return self._get_chroma_collection(question_type)

    def search_similar(self, question_type: str, query_text: str, top_k: int = 3) -> List[Dict]:
        """ìœ ì‚¬ ë¬¸ì œ ê²€ìƒ‰"""
        if self.use_pinecone:
            index = self._get_pinecone_index(question_type)
            return self._search_pinecone(index, query_text, top_k)
        else:
            collection = self._get_chroma_collection(question_type)
            return self._search_chroma(collection, query_text, top_k)

    def save_wrong_question(self, question: Dict, user_answer: str):
        """í‹€ë¦° ë¬¸ì œ ì €ì¥"""
        if self.use_pinecone:
            self._save_to_pinecone_wrong(question, user_answer)
        else:
            self._save_to_chroma_wrong(question, user_answer)

    def get_collection_count(self, question_type: str) -> int:
        """ì»¬ë ‰ì…˜/ì¸ë±ìŠ¤ì˜ ë¬¸ì œ ê°œìˆ˜"""
        if self.use_pinecone:
            index = self._get_pinecone_index(question_type)
            stats = index.describe_index_stats()
            return stats.get('total_vector_count', 0)
        else:
            collection = self._get_chroma_collection(question_type)
            return collection.count()


# ==================== LangGraph ë…¸ë“œ í•¨ìˆ˜ë“¤ ====================

def initialize_vector_db(state: Dict) -> Dict:
    """ë²¡í„° DB ì´ˆê¸°í™” ë…¸ë“œ"""

    question_type = state.get("question_type", "code")

    print(f"\n{'='*60}")
    print(f"ë²¡í„° DB í™•ì¸ ì¤‘... (íƒ€ì…: {question_type})")
    print(f"{'='*60}")

    db = QuestionVectorDB()

    # ì»¬ë ‰ì…˜ì´ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìœ¼ë©´ ì´ˆê¸°í™”
    try:
        count = db.get_collection_count(question_type)

        if count == 0:
            print(f"ì»¬ë ‰ì…˜ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...")
            db.initialize_questions(question_type)
        else:
            db_type = "Pinecone" if db.use_pinecone else "ChromaDB"
            print(f"âœ“ ê¸°ì¡´ {question_type} ë²¡í„° DB ë¡œë“œ ì™„ë£Œ ({count}ê°œ ë¬¸ì œ, {db_type})")
    except Exception as e:
        print(f"ì»¬ë ‰ì…˜ì´ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤... ({e})")
        db.initialize_questions(question_type)

    return {
        "vector_db_initialized": True,
        "messages": [{"role": "system", "content": f"{question_type} ë²¡í„° DB ì´ˆê¸°í™” ì™„ë£Œ"}]
    }


def save_wrong_question(state: Dict) -> Dict:
    """í‹€ë¦° ë¬¸ì œ ì €ì¥ ë…¸ë“œ"""

    generated_question = state.get("generated_question")
    user_answer = state.get("user_answer", "")

    if not generated_question:
        return state

    db = QuestionVectorDB()
    db.save_wrong_question(generated_question, user_answer)

    # wrong_questions ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
    wrong_questions = state.get("wrong_questions", [])
    wrong_questions.append({
        "question": generated_question,
        "user_answer": user_answer,
        "correct_answer": generated_question.get('ë‹µ', '')
    })

    return {
        "wrong_questions": wrong_questions,
        "messages": [{"role": "system", "content": "í‹€ë¦° ë¬¸ì œê°€ ë³µìŠµ DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."}]
    }
